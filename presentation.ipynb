{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy, wersja NASK\n",
    "7 kwietnia 2022\n",
    "\n",
    "Model oparty o Herberta w wersji base (https://huggingface.co/allegro/herbert-base-cased).\n",
    "Trenowany na NKJP 1M po konwersji do UD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ładowanie modelu, wersja spacy, i wyniki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"pl_nask\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"spaCy version:\", spacy.__version__)\n",
    "performance_data = nlp.meta[\"performance\"]\n",
    "acc_keys = [\"tag_acc\", \"pos_acc\", \"morph_acc\", \"dep_uas\", \"dep_las\", \"ents_f\", \"ents_r\", \"ents_p\"]\n",
    "print(\"\\nDev set results:\")\n",
    "for key in acc_keys:\n",
    "    print(key, round(performance_data[key] * 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on Test set:\n",
    "#### pl_nask\n",
    "<pre>\n",
    "\n",
    "================================== Results ==================================\n",
    "\n",
    "TOK      99.98\n",
    "TAG      96.33\n",
    "POS      98.11\n",
    "MORPH    96.71\n",
    "LEMMA    97.65\n",
    "UAS      92.87\n",
    "LAS      87.64\n",
    "NER P    90.91\n",
    "NER R    91.43\n",
    "NER F    91.17\n",
    "SENT P   99.13\n",
    "SENT R   99.09\n",
    "SENT F   99.11\n",
    "SPEED    771  \n",
    "\n",
    "\n",
    "============================== MORPH (per feat) ==============================\n",
    "\n",
    "                    P        R       F\n",
    "Animacy         96.85    97.32   97.09\n",
    "Case            98.17    98.57   98.37\n",
    "Gender          97.87    98.28   98.07\n",
    "Number          98.75    99.16   98.95\n",
    "Aspect          98.09    98.48   98.29\n",
    "Mood            99.29    99.62   99.45\n",
    "Tense           99.14    99.47   99.30\n",
    "VerbForm        98.50    98.79   98.65\n",
    "Voice           98.83    99.29   99.06\n",
    "Degree          97.64    97.85   97.75\n",
    "PunctType       99.13    99.56   99.35\n",
    "AdpType         99.00    94.16   96.52\n",
    "Variant         98.46    91.47   94.83\n",
    "Person          99.04    99.41   99.23\n",
    "Polarity        96.11    95.93   96.02\n",
    "ConjType        93.26    96.34   94.77\n",
    "Foreign         79.31    39.66   52.87\n",
    "Poss            99.74    98.24   98.98\n",
    "PronType        97.77    97.99   97.88\n",
    "Reflex          98.49   100.00   99.24\n",
    "NumType         85.99    90.03   87.96\n",
    "PrepCase        98.24    99.44   98.84\n",
    "NumForm         98.93    95.05   96.95\n",
    "VerbType        99.19    97.43   98.30\n",
    "Number[psor]    97.12    94.39   95.73\n",
    "PartType        97.46    97.87   97.66\n",
    "Hyph            95.83   100.00   97.87\n",
    "Emphatic       100.00    87.50   93.33\n",
    "PunctSide       98.57    98.57   98.57\n",
    "Abbr            98.17    95.93   97.03\n",
    "Pun             96.94    97.14   97.04\n",
    "NounForm        66.67    50.00   57.14\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "=============================== LAS (per type) ===============================\n",
    "\n",
    "                        P        R        F\n",
    "nsubj               91.24    91.84    91.54\n",
    "appos               77.13    72.88    74.94\n",
    "cop                 90.43    91.35    90.89\n",
    "root                94.95    94.21    94.58\n",
    "cc                  91.18    92.76    91.96\n",
    "conj                78.39    78.51    78.45\n",
    "case                98.01    98.21    98.11\n",
    "obl                 79.62    80.32    79.97\n",
    "advcl               79.80    81.87    80.82\n",
    "mark                91.27    91.68    91.47\n",
    "flat                92.60    90.83    91.70\n",
    "ccomp               74.16    77.23    75.66\n",
    "obj                 89.69    92.10    90.88\n",
    "advmod              87.57    90.96    89.23\n",
    "xcomp               94.12    94.37    94.24\n",
    "amod                95.44    94.98    95.21\n",
    "iobj                85.02    82.61    83.80\n",
    "nmod                70.08    69.41    69.74\n",
    "acl                 83.08    83.83    83.45\n",
    "obl:cmpr            67.97    61.54    64.60\n",
    "nmod:flat           83.13    84.84    83.98\n",
    "amod:flat           87.08    92.43    89.68\n",
    "flat:foreign       100.00    37.50    54.55\n",
    "obl:agent           92.13    91.41    91.76\n",
    "det:poss            96.93    98.19    97.55\n",
    "nmod:arg            68.29    69.03    68.66\n",
    "det                 94.19    95.78    94.98\n",
    "obl:arg             78.88    76.96    77.91\n",
    "expl:pv             98.47    98.75    98.61\n",
    "acl:relcl           82.30    82.01    82.16\n",
    "fixed               89.60    88.98    89.29\n",
    "advmod:neg          97.69    97.22    97.46\n",
    "advmod:emph         79.94    77.69    78.80\n",
    "nsubj:pass          89.19    91.24    90.21\n",
    "aux:pass            92.18    97.25    94.65\n",
    "nummod:gov          86.13    92.19    89.06\n",
    "parataxis:obj       81.18    82.04    81.61\n",
    "advcl:cmpr          74.36    72.50    73.42\n",
    "parataxis:insert    69.18    61.34    65.02\n",
    "vocative            76.53    73.53    75.00\n",
    "dep                  8.94    11.58    10.09\n",
    "discourse:intj      50.00    48.28    49.12\n",
    "xcomp:pred          67.46    61.59    64.39\n",
    "aux:imp             95.45    95.45    95.45\n",
    "ccomp:obj           79.35    70.53    74.68\n",
    "advmod:arg         100.00     4.76     9.09\n",
    "aux                 92.31    86.01    89.05\n",
    "nummod              93.90    91.72    92.80\n",
    "csubj               85.96    65.33    74.24\n",
    "det:numgov          94.20    87.84    90.91\n",
    "list                93.88    85.19    89.32\n",
    "cc:preconj          70.27    73.24    71.72\n",
    "ccomp:cleft         90.48    88.37    89.41\n",
    "aux:cnd            100.00   100.00   100.00\n",
    "xcomp:subj           0.00     0.00     0.00\n",
    "nmod:poss           91.67    78.57    84.62\n",
    "advcl:relcl         41.67    33.33    37.04\n",
    "det:nummod          96.30    94.55    95.41\n",
    "orphan               0.00     0.00     0.00\n",
    "xcomp:cleft        100.00   100.00   100.00\n",
    "obl:orphan          60.00    37.50    46.15\n",
    "nummod:flat         25.00    33.33    28.57\n",
    "nmod:pred            0.00     0.00     0.00\n",
    "csubj:pass           0.00     0.00     0.00\n",
    "\n",
    "\n",
    "=============================== NER (per type) ===============================\n",
    "\n",
    "                P       R       F\n",
    "PERSNAME    96.34   97.47   96.90\n",
    "ORGNAME     83.51   84.51   84.01\n",
    "GEOGNAME    79.53   77.10   78.29\n",
    "TIME        80.00   80.00   80.00\n",
    "PLACENAME   91.63   91.24   91.43\n",
    "DATE        88.10   91.13   89.59\n",
    "</pre>\n",
    "\n",
    "#### pl_nask_large\n",
    "\n",
    "<pre>\n",
    "\n",
    "================================== Results ==================================\n",
    "\n",
    "TOK      99.98\n",
    "TAG      96.76\n",
    "POS      98.22\n",
    "MORPH    97.15\n",
    "LEMMA    97.67\n",
    "UAS      93.01\n",
    "LAS      87.81\n",
    "NER P    91.90\n",
    "NER R    92.84\n",
    "NER F    92.37\n",
    "SENT P   98.92\n",
    "SENT R   98.95\n",
    "SENT F   98.93\n",
    "SPEED    417  \n",
    "\n",
    "\n",
    "============================== MORPH (per feat) ==============================\n",
    "\n",
    "                    P        R       F\n",
    "Animacy         97.48    97.96   97.72\n",
    "Case            98.35    98.79   98.57\n",
    "Gender          98.29    98.75   98.52\n",
    "Number          98.82    99.29   99.05\n",
    "Aspect          98.38    98.55   98.47\n",
    "Mood            99.23    99.73   99.48\n",
    "Tense           99.17    99.67   99.42\n",
    "VerbForm        98.60    98.73   98.66\n",
    "Voice           98.85    99.30   99.08\n",
    "Degree          97.48    98.00   97.74\n",
    "PunctType       99.13    99.60   99.36\n",
    "AdpType         99.47    94.11   96.72\n",
    "Variant         99.04    91.39   95.06\n",
    "Person          99.09    99.69   99.39\n",
    "Polarity        96.71    95.45   96.08\n",
    "ConjType        94.18    94.87   94.53\n",
    "Foreign         96.88    53.45   68.89\n",
    "Poss           100.00    98.99   99.49\n",
    "PronType        97.74    98.30   98.02\n",
    "Reflex          98.37   100.00   99.18\n",
    "NumType         87.09    90.91   88.96\n",
    "PrepCase        98.70    99.81   99.26\n",
    "NumForm         98.93    95.33   97.10\n",
    "VerbType        98.60    97.62   98.11\n",
    "Number[psor]    98.07    94.86   96.44\n",
    "PartType        97.85    97.02   97.44\n",
    "Hyph            97.87   100.00   98.92\n",
    "Emphatic       100.00    87.50   93.33\n",
    "PunctSide       98.57    98.57   98.57\n",
    "Abbr            97.39    97.39   97.39\n",
    "Pun             96.78    98.36   97.57\n",
    "NounForm        83.33    62.50   71.43\n",
    "\n",
    "\n",
    "=============================== LAS (per type) ===============================\n",
    "\n",
    "                        P        R       F\n",
    "nsubj               91.45    91.54   91.50\n",
    "appos               77.86    73.92   75.84\n",
    "cop                 90.55    91.46   91.00\n",
    "root                95.06    94.45   94.75\n",
    "cc                  90.80    93.23   92.00\n",
    "conj                78.78    78.96   78.87\n",
    "case                98.11    98.11   98.11\n",
    "obl                 80.39    81.12   80.75\n",
    "advcl               77.92    80.72   79.29\n",
    "mark                92.82    91.55   92.18\n",
    "flat                91.73    91.85   91.79\n",
    "ccomp               71.75    77.23   74.39\n",
    "obj                 89.26    92.66   90.93\n",
    "advmod              87.55    89.77   88.64\n",
    "xcomp               93.00    93.83   93.42\n",
    "amod                94.99    95.14   95.07\n",
    "iobj                85.40    81.60   83.46\n",
    "nmod                70.66    72.14   71.39\n",
    "acl                 84.25    83.05   83.65\n",
    "obl:cmpr            75.32    70.41   72.78\n",
    "nmod:flat           84.52    87.30   85.89\n",
    "amod:flat           85.96    92.67   89.19\n",
    "flat:foreign        50.00    25.00   33.33\n",
    "obl:agent           91.41    91.41   91.41\n",
    "det:poss            97.18    98.19   97.68\n",
    "nmod:arg            70.22    67.79   68.98\n",
    "det                 93.81    95.89   94.84\n",
    "obl:arg             80.34    76.60   78.42\n",
    "expl:pv             98.54    98.75   98.65\n",
    "acl:relcl           84.81    82.72   83.75\n",
    "advmod:neg          96.94    97.22   97.08\n",
    "advmod:emph         82.03    78.30   80.12\n",
    "nsubj:pass          93.27    89.40   91.29\n",
    "aux:pass            95.52    95.19   95.35\n",
    "nummod:gov          84.53    91.80   88.01\n",
    "det:numgov          93.66    89.86   91.72\n",
    "parataxis:obj       82.49    80.46   81.46\n",
    "advcl:cmpr          67.74    52.50   59.15\n",
    "parataxis:insert    67.41    61.52   64.33\n",
    "vocative            78.95    73.53   76.14\n",
    "discourse:intj      51.85    48.28   50.00\n",
    "dep                  8.39    12.63   10.08\n",
    "fixed               90.30    89.81   90.06\n",
    "aux:imp             95.45    95.45   95.45\n",
    "ccomp:obj           76.21    75.85   76.03\n",
    "advmod:arg          50.00     9.52   16.00\n",
    "xcomp:pred          67.72    62.32   64.91\n",
    "aux                 90.75    87.03   88.85\n",
    "nummod              92.91    91.06   91.97\n",
    "csubj               85.45    62.67   72.31\n",
    "list                90.20    85.19   87.62\n",
    "cc:preconj          76.56    69.01   72.59\n",
    "ccomp:cleft         88.10    86.05   87.06\n",
    "aux:cnd             94.12    96.97   95.52\n",
    "xcomp:subj          50.00     4.55    8.33\n",
    "nmod:poss           78.57    78.57   78.57\n",
    "advcl:relcl         33.33    26.67   29.63\n",
    "det:nummod         100.00    96.36   98.15\n",
    "xcomp:cleft         90.91   100.00   95.24\n",
    "orphan               0.00     0.00    0.00\n",
    "obl:orphan          50.00    43.75   46.67\n",
    "nummod:flat         40.00    33.33   36.36\n",
    "nmod:pred            0.00     0.00    0.00\n",
    "csubj:pass           0.00     0.00    0.00\n",
    "\n",
    "\n",
    "=============================== NER (per type) ===============================\n",
    "\n",
    "                P       R       F\n",
    "PERSNAME    96.87   97.40   97.13\n",
    "ORGNAME     85.19   87.37   86.27\n",
    "TIME        66.67   80.00   72.73\n",
    "GEOGNAME    80.66   84.35   82.46\n",
    "PLACENAME   93.00   92.31   92.65\n",
    "DATE        91.71   92.61   92.16\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skład pipeline'u:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, component in nlp.pipeline:\n",
    "    print(name, component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anotacja morfologiczna i leksykalna\n",
    "\n",
    "Informacja o tagach morfologicznych wygląda nastepująco:\n",
    "\n",
    "    tok.tag_ \n",
    "zawiera pełen tag morfologiczny w tagsecie SGJP\n",
    "\n",
    "    tok.pos_\n",
    "zawiera klasę części mowy w tagsecie UPOS\n",
    "\n",
    "    tok.morph\n",
    "zawiera cechy morfologiczne w tagsecie UFEATS\n",
    "\n",
    "    tok.lemma_\n",
    "zawiera lemat pochodzący z analiz Morfeusza, dezambiguowanych przez tok.tag_ oraz dane frekwencyjne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "def table_tags(doc):\n",
    "    tok_dicts = []\n",
    "    for tok in doc:\n",
    "        tok_dict = {\n",
    "                    \"orth\": tok.orth_,\n",
    "                    \"lemma\": tok.lemma_,\n",
    "                    \"UPOS\": tok.pos_,\n",
    "                    \"SGJP\": tok.tag_,}\n",
    "        tok_dicts.append(tok_dict)\n",
    "    return pandas.DataFrame(tok_dicts)\n",
    "\n",
    "def table_morphs(doc):\n",
    "    tok_dicts = []\n",
    "    for tok in doc:\n",
    "        tok_dict = {\n",
    "                    \"orth\": tok.orth_,\n",
    "                    \"lemma\": tok.lemma_,\n",
    "                    \"UFEAT\": str(tok.morph)[:40]}\n",
    "        tok_dicts.append(tok_dict)\n",
    "    return pandas.DataFrame(tok_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"Ani skuteczna dyplomacja, ani moralne wsparcie, ani profetyczne gesty. \\\n",
    "Tak podsumować można linię Stolicy Apostolskiej w czasie wojny w Ukrainie. \\\n",
    "Rosyjska agresja boleśnie zweryfikowała teologię pokoju i wizję geopolityczną papieża.\"\n",
    "doc = nlp(txt)\n",
    "print(table_tags(doc), \"\\n\\n\")\n",
    "print(table_morphs(doc), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obsługujemy prostą, słownikową dedyminutywizację: Z SGJP i Wiktionary zebraliśmy ponad 6 tys. par zdrobnienie - forma bazowa, które wykorzystujemy, słownik ten można rozbudowywać, znajduje się w plikach modelu.\n",
    "\n",
    "    tok._.is_diminutive\n",
    "wartość logiczna opisująca czy dany token wyraża zdrobnienie\n",
    "\n",
    "    tok._.diminutive_chain\n",
    "lista zdrobnień w łańcuchu aż do ostatniej formy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"Spotkałem się z Alą, żeby porozmawiać o jej milutkim synku - Piotrusiu. Ona jest wspaniałą mamusią.\"\n",
    "doc2 = nlp(txt)\n",
    "for tok in doc2:\n",
    "    print(tok.i, tok.orth_, tok.lemma_, tok._.is_diminutive, tok._.diminutive_chain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morfeusz zwraca również kilka kwalifikatorów o charakterze leksykalnym, zapisujemy je w rozszerzonych atrybutach:\n",
    "\n",
    "    tok._.properness\n",
    "lista kwalifikatorów opisujących pospolitość/własność rzeczowników.\n",
    "\n",
    "    tok._.disambiguator\n",
    "\"rozpodabniacz\", rozróżniający różne leksemy, o identycznie brzmiących lematach, ale różnych wzorcach odmiany.\n",
    "\n",
    "    tok._.style\n",
    "lista kwalifikatorów dotyczących m.in. nacechowania stylistycznego.\n",
    "\n",
    "    tok._.is_ign\n",
    "atrybut określający, czy wskazane słowo jest poza słownikiem morfeusza, atrybut ten można wykorzystywać zamiast tok.is_oov, którego to nie można nadpisać, i jest normalnie ustawiane na podstawie embeddingów word2vec, których w tym modelu nie stosujemy\n",
    "\n",
    "    tok._.freq\n",
    "częstość bezwzględna danego lematu w NKJP1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_additional_annotations(doc):\n",
    "    tok_dicts = []\n",
    "    for tok in doc:\n",
    "        tok_dict = {\n",
    "                    \"orth\": tok.orth_,\n",
    "                    \"properness\": tok._.properness,\n",
    "                    \"disambiguator\": tok._.disambiguator,\n",
    "                    \"style\": tok._.style,\n",
    "                    \"ign\": tok._.is_ign,\n",
    "                    \"freq\": tok._.freq\n",
    "        }\n",
    "        tok_dicts.append(tok_dict)\n",
    "    return pandas.DataFrame(tok_dicts)\n",
    "\n",
    "txt2 = \"A to zwykłe mendy, co im zawiniły firanki?!? Podaj mi francuzy, s'il vous plait\"\n",
    "doc2 = nlp(txt2)\n",
    "\n",
    "print(table_additional_annotations(doc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regułowe wyszukiwanie wzorców\n",
    "\n",
    "(https://spacy.io/usage/rule-based-matching)\n",
    "\n",
    "SpaCy umożliwia wyszukiwanie w tekście wzorców. Wzorce opisują ciągłe sekwencje tokenów, w terminach udostępnianych przez SpaCy atrybutów tokenów. Liczba obsługiwanych atrybutów oraz ekspresywność warunków jakie możemy formułować przekracza zakres tej prezentacji, natomiast możemy wskazać kilka podstawowych funkcjonalności.\n",
    "\n",
    "Wzorce mogą być również definiowane w terminach UFEATS, wówczas porównujemy nie pojedyncze wartości, a słowniki wartości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "pattern_fem_sing = [{\"MORPH\": {\"IS_SUPERSET\": [\"Number=Sing\", \"Gender=Fem\"]}}]\n",
    "\n",
    "matcher = Matcher(nlp.vocab, validate=True)\n",
    "matcher.add(\"FemSing\", [pattern_fem_sing])\n",
    "\n",
    "matches = matcher(doc)\n",
    "for match in matches:\n",
    "    rule_identifier, start, end = match\n",
    "    rule_name = nlp.vocab.strings[rule_identifier]\n",
    "    print(f\"{rule_name}: {doc[start:end]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.remove(\"FemSing\")\n",
    "pattern_fem_sing_noun = [{\"MORPH\": {\"IS_SUPERSET\": [\"Number=Sing\", \"Gender=Fem\"]},\n",
    "                          \"POS\": \"NOUN\"}]\n",
    "matcher.add(\"FemSingNoun\", [pattern_fem_sing_noun])\n",
    "\n",
    "matches = matcher(doc)\n",
    "for match in matches:\n",
    "    rule_identifier, start, end = match\n",
    "    rule_name = nlp.vocab.strings[rule_identifier]\n",
    "    print(f\"{rule_name}: {doc[start:end]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.remove(\"FemSingNoun\")\n",
    "pattern_fem_sing_adj_noun = [{\"MORPH\": {\"IS_SUPERSET\": [\"Number=Sing\", \"Gender=Fem\"]},#Pierwszy token\n",
    "                          \"POS\": \"ADJ\"},\n",
    "                         {\"MORPH\": {\"IS_SUPERSET\": [\"Number=Sing\", \"Gender=Fem\"]},# Drugi token\n",
    "                          \"POS\": \"NOUN\"}]\n",
    "matcher.add(\"FemSingAdjNoun\", [pattern_fem_sing_adj_noun])\n",
    "pattern_fem_sing_noun_adj = [{\"MORPH\": {\"IS_SUPERSET\": [\"Number=Sing\", \"Gender=Fem\"]},#Pierwszy token\n",
    "                          \"POS\": \"NOUN\"},\n",
    "                         {\"MORPH\": {\"IS_SUPERSET\": [\"Number=Sing\", \"Gender=Fem\"]},# Drugi token\n",
    "                          \"POS\": \"ADJ\"}]\n",
    "matcher.add(\"FemSingNounAdj\", [pattern_fem_sing_noun_adj])\n",
    "\n",
    "matches = matcher(doc)\n",
    "for match in matches:\n",
    "    rule_identifier, start, end = match\n",
    "    rule_name = nlp.vocab.strings[rule_identifier]\n",
    "    print(f\"{rule_name}: {doc[start:end]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsowanie zależnościowe\n",
    "Parser wytrenowano na NKJP 1M w wersji UD, zgodnym z anotacją PDB. Dane są częściowo anotowane ręcznie, częściowo automatycznie (COMBO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style='dep',jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regułowe wyszukiwanie wzorców w drzewach zależnościowych\n",
    "\n",
    "(https://spacy.io/usage/rule-based-matching)\n",
    "\n",
    "W języku polskim wymóg odgórnego określania kolejności tokenów, oraz ciągłości sekwencji może być mocno ograniczający. Możemy więc wykorzystać narzędzie o większej mocy, pozwalające definiować wzorce w terminach położenia w drzewie zależnościowym (które może być zgoła odmienne od horyzontalnego porządku tokenów w tekście)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import DependencyMatcher\n",
    "\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "\n",
    "dep_noun_adj = \\\n",
    "[\n",
    "    {\n",
    "        \"RIGHT_ID\": \"noun\",\n",
    "        \"RIGHT_ATTRS\": {\"POS\": \"NOUN\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"noun\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"modifier\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"amod\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "matcher.add(\"NounAdj\", [dep_noun_adj])\n",
    "matches = matcher(doc)\n",
    "for match in matches:\n",
    "    rule_identifier, matching_tokens = match\n",
    "    rule_name = nlp.vocab.strings[rule_identifier]\n",
    "    ordered_phrase = [doc[tok_i] for tok_i in sorted(matching_tokens)]\n",
    "    print(f\"{rule_name}: {ordered_phrase}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordination = [{\n",
    "        \"RIGHT_ID\": \"subordinate\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"conj\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"subordinate\",\n",
    "        \"REL_OP\": \"<\",\n",
    "        \"RIGHT_ID\": \"superior\",\n",
    "        \"RIGHT_ATTRS\": {}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"subordinate\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"cc\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"cc\", \"cc:preconj\"]}}\n",
    "    }]\n",
    "    \n",
    "\n",
    "from spacy.matcher import DependencyMatcher\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "matcher.add(\"Coordination\", [coordination])\n",
    "matches = matcher(doc)\n",
    "for match in matches:\n",
    "    rule_identifier, matching_tokens = match\n",
    "    rule_name = nlp.vocab.strings[rule_identifier]\n",
    "    ordered_phrase = [doc[tok_i] for tok_i in sorted(matching_tokens)]\n",
    "    print(f\"{rule_name}: {ordered_phrase}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rozpoznawanie jednostek nazewniczych\n",
    "\n",
    "Model obsługuje 5 podstawowych kategorii opisanych w NKJP:\n",
    "PLACENAME, GEOGNAME, PERSNAME, TIME, DATE\n",
    "\n",
    "Nie obsługujemy jednostek zazębiających się (a więc również jednostek zagnieżdżonych)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Przetwarzanie batchy tekstów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchids =\"Storczykowate są rodziną kosmopolityczną, występującą na wszystkich kontynentach, z wyjątkiem Antarktydy. Największe zróżnicowanie gatunkowe storczyków występuje w strefie międzyzwrotnikowej, a zwłaszcza w tropikach na kontynentach amerykańskich i w Azji południowo-wschodniej po Nową Gwineę. W tropikach amerykańskich rośnie 350 rodzajów i ok. 10 tys. gatunków, tylko w Malezji jest ich 4,5 tys. gatunków, a na Nowej Gwinei 2,3 tys. Z tropikami związanych jest 36 najbardziej zróżnicowanych gatunkowo rodzajów, liczących ponad 100 gatunków, i tylko nieliczne z nich mają przedstawicieli poza strefą równikową.\"\n",
    "nettles = \"Pokrzywa – rodzaj jednorocznych roślin zielnych lub bylin z rodziny pokrzywowatych (Urticaceae Juss.). Należy do niej co najmniej 68 gatunków rozpowszechnionych na całej kuli ziemskiej z wyjątkiem Antarktydy. Rośliny niektórych gatunków dostarczają włókna i są jadalne. \"\n",
    "bridge = \"Brydż (ang. bridge) – logiczna gra karciana, w której bierze udział czterech graczy tworzących dwie rywalizujące ze sobą pary[2]. Gracze stanowiący parę siedzą naprzeciwko siebie. Każda para stara się uzyskać lepszy wynik punktowy od wyniku przeciwników. Gra składa się z dwóch odrębnych części: licytacji oraz rozgrywki. Podczas licytacji gracze deklarują wzięcie pewnej minimalnej liczby lew oraz wskazują kolor atutowy lub jego brak, a najwyższa deklaracja staje się kontraktem ostatecznym, z którego trzeba się wywiązać podczas drugiej części zwanej rozgrywką.\"\n",
    "jokers = \"Joker (wym. „dżoker” czyli ang. żartowniś), dżoker – jedna z kart do gry, w niektórych grach karcianych (na przykład kierki) służy do zastępowania dowolnej innej karty. W standardowej brydżowej talii kart znajdują się dwa lub trzy jokery oprócz 52 kart zwykłych. Najczęściej spotykanym wizerunkiem na jokerze jest kolorowo ubrany błazen (trefniś, ang. joker od joke – „żart”, z łac. iocus czytaj jokus) w czapce z dzwoneczkami. Jokery oprócz wizerunku błazna bywają oznaczane w narożniku karty gwiazdką lub (niekiedy, jeśli nie koliduje to z oznaczeniem waleta) literą J; spotykane są też inne oznaczenia, na przykład znakiem dolara.\"\n",
    "tanks = \"Pierwsze czołgi brytyjskie przypominały opancerzone skrzynie, opasane z dwóch stron metalowymi gąsienicami. Nowy rodzaj mechanizmu jezdnego umożliwiał pokonywanie trudnych przeszkód, w tym okopów, a także miażdżenie zasieków z drutu kolczastego. Pierwsze czołgi były maszynami bardzo prymitywnymi. Aby wykonać ostry skręt, wymagały skoordynowanej pracy czterech osób, co było nie lada osiągnięciem. Pojazd nie miał wentylacji, co powodowało, że gazy spalinowe i prochowe wywoływały często omdlenia i zatrucia załogi.\"\n",
    "pistol = \"Pistolet – krótka, ręczna broń palna (z wyłączeniem rewolwerów) zasilana najczęściej amunicją pistoletową, rzadziej rewolwerową (słabszą od karabinowej i pośredniej). Pistolety przeznaczone są do walki na krótkim dystansie (do 50 m). Charakteryzują się krótką lufą, małymi gabarytami i chwytem (rękojeścią) przystosowanym do strzelania z jednej ręki. Najpowszechniej stosowane w wojsku, policji i ochronie. Są także popularną bronią sportową. \"\n",
    "pope = \"Biskupi Rzymu oparli swój prymat na sukcesji apostolskiej, zgodnie z tradycją, według której pierwszym biskupem Rzymu był Piotr Apostoł, który zginął tam śmiercią męczeńską. Nowy Testament milczy wprawdzie na ten temat i wspomina tylko o podróży św. Piotra do Antiochii (Gal 2, 11), a w zakończeniu Listu do Rzymian Pawła Apostoła pośród licznych osób Piotr nie jest wymieniony, ale o pobycie apostoła w Rzymie mówią inne pisma z pierwszych wieków istnienia chrześcijaństwa, m.in. list biskupa Antiochii Ignacego do Kościoła w Rzymie, napisany za panowania cesarza Trajana (98–117).\"\n",
    "knights = \"Wpływ na powstanie tej grupy miały przemiany społeczno-polityczne na terenie dawnego imperium Karolingów. Wiązały się one z kryzysem władzy centralnej i kształtowaniem się stosunków zależności feudalnej. Równocześnie nastąpił wzrost znaczenia ciężkiej konnicy w prowadzeniu wojen, powodujące zapotrzebowanie na konnych wojowników.\"\n",
    "george = \"We w pełni rozwiniętej wersji zachodniej smok zrobił sobie gniazdo na źródle, którego woda zaopatrywała miasto Silene (prawdopodobnie późniejsza Cyrena w Libii) lub miasto Lod, zależnie od źródeł. W konsekwencji mieszkańcy musieli prosić smoka o opuszczenie gniazda na czas, gdy nabierali wodę. Każdego dnia oferowali mu owcę, a jeśli jej nie znaleźli, musieli oddać zamiast niej jedną dziewczynę. Ofiara była wybierana przez losowanie.\"\n",
    "greece = \"Grecja pozostaje pod wpływem klimatu śródziemnomorskiego. Cechuje go łagodna zima z suchym, gorącym latem. W najcieplejszym miesiącu średnia temperatura wynosi ponad 22 °C. Są co najmniej cztery miesiące ze średnią temperaturą ponad 10 °C, w zimie mogą zdarzać się przymrozki. Notuje się co najmniej trzy razy więcej opadów atmosferycznych w najwilgotniejszych miesiącach zimowych w porównaniu z suchym latem.\"\n",
    "italy = \"W epoce żelaza tereny Włoch zamieszkiwali Ligurowie i Sykulowie, a także liczne inne plemiona italskie, celtyckie i iliryjskie. W okresie starożytności tereny Włoch znalazły się pod panowaniem Rzymian. Przed okresem rzymskim tereny Włoch były zamieszkiwane przez Fenicjan i Greków. Od średniowiecza do Risorgimento, pomimo że Półwysep Apeniński był spójny pod względem językowym i kulturowym, jego historia składała się z dziejów niezależnych republik i księstw oraz obcych posiadłości i stref wpływów.\"\n",
    "\n",
    "texts = [orchids, nettles, jokers, bridge, tanks, pistol, pope, knights, george, greece, italy]\n",
    "dox = list(nlp.pipe(texts))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podobieństwo semantyczne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"orchids \", \"nettles\", \"bridge \", \"jokers \", \"tanks \", \"pistol \",\n",
    "          \"pope \", \"knights \", \"george \", \"greece \", \"italy \"]\n",
    "sim_matr = []\n",
    "for x in dox:\n",
    "    sim_matr.append([])\n",
    "    for y in dox:\n",
    "        sim_matr[-1].append(round(x.similarity(y), 3))\n",
    "\n",
    "import numpy\n",
    "arr = numpy.array(sim_matr)\n",
    "doc_sim = pandas.DataFrame(arr, columns=labels, index=labels)\n",
    "print(doc_sim)\n",
    "\n",
    "from itertools import product\n",
    "tokpairs = []\n",
    "for x_i in range(len(dox)):\n",
    "    doc_x = dox[x_i]\n",
    "    for y_i in range(x_i+1, len(dox)):\n",
    "        doc_y = dox[y_i]\n",
    "        tok_prod = product(doc_x, doc_y)\n",
    "        for t1, t2 in tok_prod:\n",
    "            sim = round(t1.similarity(t2), 3)\n",
    "            if sim == 1.0:\n",
    "                continue\n",
    "            tokpairs.append((t1, t2, sim))\n",
    "\n",
    "ranking = sorted(tokpairs, key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "for x in ranking[:50]:\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dostęp do wektorów dla dokumentów, tokenów, spanów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchid_doc = dox[0]\n",
    "doc_vec = orchid_doc.vector\n",
    "tok_vec = orchid_doc[0].vector\n",
    "span_vec = orchid_doc[:3].vector\n",
    "sent_vec = list(orchid_doc.sents)[0].vector\n",
    "print(sent_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexer\n",
    "\n",
    "Flexer pozwala, w oparciu o Morfeusza, na odmianę pojedynczych wyrazów, a także fraz. Akceptuje więc pojedyncze tokeny, a także ich listy (niekoniecznie ciągłe).\n",
    "\n",
    "Dostęp do niego odbywa się poprzez komponent \"Morfeusz\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orchid_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morf_component = nlp.get_pipe(\"morfeusz\")\n",
    "family = orchid_doc[2]\n",
    "target_morph = \"gen:pl\"\n",
    "inflected = morf_component.flex(family, target_morph)\n",
    "print(f\"{family} -({target_morph})-> {inflected}\")\n",
    "\n",
    "phrase = orchid_doc[2:4]\n",
    "inflected = morf_component.flex(phrase, target_morph)\n",
    "print(f\"{phrase} -({target_morph})-> {inflected}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_contiguous = [orchid_doc[32], orchid_doc[41]]\n",
    "target_morph = \"inst\"\n",
    "inflected = morf_component.flex(non_contiguous, target_morph)\n",
    "print(f\"{non_contiguous} -({target_morph})-> {inflected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorytm Flexera jest również do wykorzystania w procesie lematyzacji wyrażeń złożonych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tanks_doc = dox[4]\n",
    "print(tanks_doc)\n",
    "\n",
    "tanks_phrase = tanks_doc[4:13]\n",
    "lemmatized = morf_component.lemmatize(tanks_phrase)\n",
    "print(\"\\n\")\n",
    "print(f\"{tanks_phrase} -> {lemmatized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntxt = \"\"\"Informuję, że moim identyfikatorem podatkowym, którym posługuję się w rozliczeniach podatkowych z Urzędem Skarbowym jest: Numer PESEL 75123202570 (Niepotrzebne skreślić). Adres do wskazania w PIT: ul. Krauthofera 18a/27, 61-203 Poznań.\n",
    "2. Pośrednik kredytu hipotecznego: Powszechna Kasa Oszczędności Bank Polski Spółka Akcyjna siedzibą w Warszawie przy ul. Puławskiej 15, 02-515 Warszawa, http://www.pkobp.pl; infolinia 800 302 302. \n",
    "Prezentowany wykaz dokumentów jest wspólny dla: -_ Powszechnej Kasy Oszczędnościowej Banku Polskiego Spółki Akcyjnej z siedzibą w Warszawie przy ul. Puławskiej 15, 02-515 Warszawa, zwanej dalej „PKO Bank Polski SA”, - PKO Banku Hipotecznego Spółki Akcyjnej z siedzibą w Gdyni przy ul. Jerzego Waszyngtona 17, 81-342 Gdynia, zwanej dalej „PKO Bank Hipoteczny SA”.\n",
    "\\\n",
    "\"\n",
    "\n",
    "Wskazówki dla lekarza kierującego: 1. w zakresie diagnostyki: brak 2; w zakresie farmakoterapii: zyx,entom; 3. inne: brak; Anna Sosnowska - Specjalista gardła, foniatra 160-288 Poznań, l. Promienista 347. \n",
    "\n",
    "\"\n",
    "\"\"\"\n",
    "doc = nlp(ntxt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NASK",
   "language": "python",
   "name": "nask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
